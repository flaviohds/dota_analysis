{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dota_update_data.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPW0LP3G2t5xqmDNjdgDOmb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/flaviohds/dota_analysis/blob/branch1/dota_update_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYbm-5rSSsoV"
      },
      "source": [
        "import pandas as pd\n",
        "import time\n",
        "from datetime import datetime\n",
        "import pytz\n",
        "from numpy import NaN"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7cJq2CIuKAL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52044c6f-4b0b-4cbf-b642-ab68fc261c8c"
      },
      "source": [
        "!pip install selenium # mimics user clicks\n",
        "!apt-get update # to update ubuntu to correctly run apt install\n",
        "!apt install chromium-chromedriver #install chrome on the scrapper server\n",
        "\n",
        "import sys\n",
        "sys.path.insert(0,'/usr/lib/chromium-browser/chromedriver')\n",
        "\n",
        "from selenium import webdriver\n",
        "\n",
        "#chrome options that reduces bugs and variability\n",
        "chrome_options = webdriver.ChromeOptions() \n",
        "chrome_options.add_argument('--headless')\n",
        "chrome_options.add_argument('--no-sandbox')\n",
        "chrome_options.add_argument('--disable-dev-shm-usage')\n",
        "chrome_options.add_argument('--start-maximized')\n",
        "chrome_options.add_argument('user-agent=Mozilla/5.0 (Windows NT 6.3; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/59.0.3071.115 Safari/537.36')\n",
        "chrome_options.add_argument('--ignore-certificate-errors')\n",
        "wd = webdriver.Chrome('chromedriver',chrome_options=chrome_options, service_args=['--verbose', '--log-path=/tmp/chromedriver.log'])"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting selenium\n",
            "  Downloading selenium-4.3.0-py3-none-any.whl (981 kB)\n",
            "\u001b[K     |████████████████████████████████| 981 kB 28.8 MB/s \n",
            "\u001b[?25hCollecting trio-websocket~=0.9\n",
            "  Downloading trio_websocket-0.9.2-py3-none-any.whl (16 kB)\n",
            "Collecting urllib3[secure,socks]~=1.26\n",
            "  Downloading urllib3-1.26.9-py2.py3-none-any.whl (138 kB)\n",
            "\u001b[K     |████████████████████████████████| 138 kB 27.3 MB/s \n",
            "\u001b[?25hCollecting trio~=0.17\n",
            "  Downloading trio-0.21.0-py3-none-any.whl (358 kB)\n",
            "\u001b[K     |████████████████████████████████| 358 kB 56.9 MB/s \n",
            "\u001b[?25hCollecting outcome\n",
            "  Downloading outcome-1.2.0-py2.py3-none-any.whl (9.7 kB)\n",
            "Collecting sniffio\n",
            "  Downloading sniffio-1.2.0-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (21.4.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (2.4.0)\n",
            "Collecting async-generator>=1.9\n",
            "  Downloading async_generator-1.10-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (2.10)\n",
            "Collecting wsproto>=0.14\n",
            "  Downloading wsproto-1.1.0-py3-none-any.whl (24 kB)\n",
            "Collecting cryptography>=1.3.4\n",
            "  Downloading cryptography-37.0.4-cp36-abi3-manylinux_2_24_x86_64.whl (4.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.1 MB 10.9 MB/s \n",
            "\u001b[?25hCollecting pyOpenSSL>=0.14\n",
            "  Downloading pyOpenSSL-22.0.0-py2.py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 4.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from urllib3[secure,socks]~=1.26->selenium) (2022.6.15)\n",
            "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from urllib3[secure,socks]~=1.26->selenium) (1.7.1)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=1.3.4->urllib3[secure,socks]~=1.26->selenium) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=1.3.4->urllib3[secure,socks]~=1.26->selenium) (2.21)\n",
            "Collecting h11<1,>=0.9.0\n",
            "  Downloading h11-0.13.0-py3-none-any.whl (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 6.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from h11<1,>=0.9.0->wsproto>=0.14->trio-websocket~=0.9->selenium) (4.1.1)\n",
            "Installing collected packages: sniffio, outcome, h11, cryptography, async-generator, wsproto, urllib3, trio, pyOpenSSL, trio-websocket, selenium\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "requests 2.23.0 requires urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1, but you have urllib3 1.26.9 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed async-generator-1.10 cryptography-37.0.4 h11-0.13.0 outcome-1.2.0 pyOpenSSL-22.0.0 selenium-4.3.0 sniffio-1.2.0 trio-0.21.0 trio-websocket-0.9.2 urllib3-1.26.9 wsproto-1.1.0\n",
            "Hit:1 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Get:3 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Hit:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:6 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Get:7 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Ign:8 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:9 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:10 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:11 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Hit:12 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [1,075 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,298 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [3,302 kB]\n",
            "Get:16 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [2,075 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,521 kB]\n",
            "Get:18 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [1,063 kB]\n",
            "Get:20 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,871 kB]\n",
            "Get:21 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [1,031 kB]\n",
            "Fetched 15.5 MB in 9s (1,641 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  chromium-browser chromium-browser-l10n chromium-codecs-ffmpeg-extra\n",
            "Suggested packages:\n",
            "  webaccounts-chromium-extension unity-chromium-extension\n",
            "The following NEW packages will be installed:\n",
            "  chromium-browser chromium-browser-l10n chromium-chromedriver\n",
            "  chromium-codecs-ffmpeg-extra\n",
            "0 upgraded, 4 newly installed, 0 to remove and 66 not upgraded.\n",
            "Need to get 89.8 MB of archives.\n",
            "After this operation, 302 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-codecs-ffmpeg-extra amd64 101.0.4951.64-0ubuntu0.18.04.1 [1,142 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-browser amd64 101.0.4951.64-0ubuntu0.18.04.1 [78.5 MB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-browser-l10n all 101.0.4951.64-0ubuntu0.18.04.1 [4,980 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-chromedriver amd64 101.0.4951.64-0ubuntu0.18.04.1 [5,153 kB]\n",
            "Fetched 89.8 MB in 2s (38.7 MB/s)\n",
            "Selecting previously unselected package chromium-codecs-ffmpeg-extra.\n",
            "(Reading database ... 155639 files and directories currently installed.)\n",
            "Preparing to unpack .../chromium-codecs-ffmpeg-extra_101.0.4951.64-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-codecs-ffmpeg-extra (101.0.4951.64-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package chromium-browser.\n",
            "Preparing to unpack .../chromium-browser_101.0.4951.64-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-browser (101.0.4951.64-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package chromium-browser-l10n.\n",
            "Preparing to unpack .../chromium-browser-l10n_101.0.4951.64-0ubuntu0.18.04.1_all.deb ...\n",
            "Unpacking chromium-browser-l10n (101.0.4951.64-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package chromium-chromedriver.\n",
            "Preparing to unpack .../chromium-chromedriver_101.0.4951.64-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-chromedriver (101.0.4951.64-0ubuntu0.18.04.1) ...\n",
            "Setting up chromium-codecs-ffmpeg-extra (101.0.4951.64-0ubuntu0.18.04.1) ...\n",
            "Setting up chromium-browser (101.0.4951.64-0ubuntu0.18.04.1) ...\n",
            "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/x-www-browser (x-www-browser) in auto mode\n",
            "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/gnome-www-browser (gnome-www-browser) in auto mode\n",
            "Setting up chromium-chromedriver (101.0.4951.64-0ubuntu0.18.04.1) ...\n",
            "Setting up chromium-browser-l10n (101.0.4951.64-0ubuntu0.18.04.1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
            "Processing triggers for mime-support (3.60ubuntu1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.3) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: DeprecationWarning: use options instead of chrome_options\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqGAGceVbapL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e86eca7b-e0b1-4467-d939-5ef9e1b48b8e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/') #mount drive on google drive\n",
        "\n",
        "import os\n",
        "os.chdir(\"drive/My Drive/dota\") #map the folder on google drive"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vijWT423Qjjy"
      },
      "source": [
        "#function updates heroes and abilities/spells/skills names from www.dota2.com/heroes\n",
        "#updates up to last_hero\n",
        "#returns True if there are new heroes or abilities\n",
        "def update_hero_list(last_hero='ZEUS',hero_filename_o='hero_list.xlsx'):\n",
        "  print('updating heroes names and skills')\n",
        "  print('expected time: ~12mins')\n",
        "  wd.delete_all_cookies()\n",
        "  wd.get(\"https://www.dota2.com/hero/abaddon\")\n",
        "  wd.page_source;\n",
        "  time.sleep(2)\n",
        "  \n",
        "  hero_list=[]\n",
        "  hero_count=0\n",
        "  is_last_hero=False\n",
        "  spells_row=[]\n",
        "  print('heroes checked so far:')\n",
        "  #loop to iterate heroes\n",
        "  while is_last_hero==False:\n",
        "    hero_count+=1\n",
        "    hero_name=wd.find_element('xpath','/html/body/div[2]/div/div/div[2]/div[5]/div[2]')\n",
        "    if hero_name.text==last_hero:\n",
        "      is_last_hero=True\n",
        "    hero_row=[]\n",
        "    hero_row.append(hero_name.text)\n",
        "\n",
        "    j=0\n",
        "    is_last_spell=False\n",
        "    spell_row=[]\n",
        "    #loop to iterate spells\n",
        "    while is_last_spell==False:\n",
        "      spell_name=wd.find_element('xpath','//*[@id=\"dota_react_root\"]/div/div/div[4]/div[1]/div[2]/div[2]/div/div[1]/div/div[1]')\n",
        "      spell_row.append(spell_name.text)\n",
        "\n",
        "      try: #check if the next spell button exists\n",
        "        ab_xpath='//*[@id=\"dota_react_root\"]/div/div/div[4]/div[1]/div[2]/div[1]/div[2]/div['+str(j+2)+']'\n",
        "        next_spell_b=wd.find_element('xpath',ab_xpath)\n",
        "        next_spell_b.click()\n",
        "      except: #if not, set the loop to end\n",
        "        is_last_spell=True\n",
        "      time.sleep(0.5)\n",
        "      j+=1\n",
        "\n",
        "    spell_row=list(dict.fromkeys(spell_row)) #removes duplicates\n",
        "    hero_row.extend(spell_row)\n",
        "    hero_list.append(hero_row)\n",
        "    print(hero_name.text,end='\\t')\n",
        "    if hero_count%10==0:\n",
        "      print('')\n",
        "    next_hero_b=wd.find_element('xpath','/html/body/div[2]/div/div/div[2]/div[2]/a[3]') #assign the next hero button\n",
        "    next_hero_b.click() #click the next hero button\n",
        "    time.sleep(1)\n",
        "\n",
        "  print()\n",
        "  df_hero_list=pd.DataFrame(hero_list) #creates the dataframe\n",
        "  n_skills=df_hero_list.shape[1]-1 #checks the dimension of the dataframe to get the length of the hero with the highest number of spells\n",
        "  columns_names=['hero'] #first column is the hero name\n",
        "  for i in range(n_skills):\n",
        "    columns_names.append('skill '+str(i+1)) #creates a list of columns names based with 'hero','skill 1','skill 2',...\n",
        "  df_hero_list.columns=columns_names #attributes the columns names to the header\n",
        "\n",
        "  try: #checks if a hero list file exists\n",
        "    df_hero_list_old=pd.read_excel(hero_filename_o,index_col=0)\n",
        "  except: #if its not found, set the dataframe to empty\n",
        "    df_hero_list_old=pd.DataFrame([])\n",
        "    print('no old '+hero_filename_o+'file found. creating a new one...')\n",
        "    \n",
        "  if df_hero_list.equals(df_hero_list_old)==True: #check if the new list is equal to the existing one\n",
        "    print('failed to find new heroes or abilities to update')\n",
        "    return False\n",
        "  else: #if its not equal, update the list\n",
        "    df_hero_list.to_excel(hero_filename_o)\n",
        "    if df_hero_list_old.empty:\n",
        "      print('no old '+hero_filename_o+'file found. creating a new one...')\n",
        "      print('created '+hero_filename_o+' with the newest abilities/heroes')\n",
        "    else:\n",
        "      print('updated '+hero_filename_o+' with new abilities/heroes')\n",
        "\n",
        "    return True"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#function updates the skills on the skills_list file\n",
        "def update_skills_list(skill_filename_o='skills_list.xlsx',hero_filename_i='hero_list.xlsx'):\n",
        "  try:\n",
        "    df_hero_list=pd.read_excel(hero_filename_i,index_col=0)\n",
        "  except:\n",
        "    print('error loading '+hero_filename_i+' as the hero list')\n",
        "    return\n",
        "  skills_list=[]\n",
        "\n",
        "  for i in df_hero_list.index: #iterates rows\n",
        "    for j in df_hero_list.columns: #iterates columns\n",
        "      if type(df_hero_list[j][i])==str: #checks if its a valid cell (not a NaN cell)\n",
        "        skills_list.append(df_hero_list[j][i])\n",
        "  df_skills_list=pd.DataFrame(skills_list,columns=['skill'])\n",
        "\n",
        "  blacklist=['SPIRITS IN','SPIRITS OUT','ATTRIBUTE SHIFT (STRENGTH GAIN)'] #skills to remove from the list\n",
        "  mask=df_skills_list.isin(blacklist)['skill'] #mask of where the blacklisted skills are ([0] to convert to a pandas.series)\n",
        "  blacklist_indexes=df_skills_list[mask].index #indexes of where the blacklisted skills are\n",
        "  df_skills_list=df_skills_list.drop(blacklist_indexes) #remove the blacklisted skills\n",
        "  df_skills_list=df_skills_list.reset_index(drop=True)\n",
        "  df_skills_list.to_excel(skill_filename_o)"
      ],
      "metadata": {
        "id": "BD0D1A_nhgPk"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#function copies the attributes from the old attributed skill list and overrides it\n",
        "#uses a backup file if needed. does not override the backup\n",
        "def update_attribute_data(skills_list_new_filename_i='skills_list.xlsx', skills_attributed_filename_io='skills_list_attributed.xlsx',\n",
        "                          skills_list_attributed_backup_i='skills_list_attributed_backup.xlsx', sort=True):\n",
        "  \n",
        "  #handles missing attributed and/or missing backupfiles aswell as\n",
        "  #\"skill_list_attributed\" files that do not have any attributes assigned\n",
        "  try:\n",
        "    df_old=pd.read_excel(skills_attributed_filename_io,index_col=0)\n",
        "    if df_old.shape[1]<2:\n",
        "      print(skills_attributed_filename_io+' file has no attributes, attempting to use backup file: '+skills_list_attributed_backup_i)\n",
        "      try:\n",
        "        df_old=pd.read_excel(skills_list_attributed_backup_i,index_col=0)\n",
        "      except:\n",
        "        print('error using backup file '+skills_list_attributed_backup_i+' , aborting update_attribute_data()')\n",
        "        return\n",
        "      if df_old.shape[1]<2:\n",
        "        print('backup file also does not have attributes, aborting update_attribute_data()')\n",
        "        return\n",
        "  except:\n",
        "    print('error using '+skills_attributed_filename_io+' for attributed skill list')\n",
        "    print('attempting to use backup file: '+skills_list_attributed_backup_i)\n",
        "    try:\n",
        "      df_old=pd.read_excel(skills_list_attributed_backup_i,index_col=0)\n",
        "    except:\n",
        "      print('error using backup file '+skills_list_attributed_backup_i+' , aborting update_attribute_data()')\n",
        "      return\n",
        "    if df_old.shape[1]<2:\n",
        "      print('backup file does not have attributes, aborting update_attribute_data()')\n",
        "      return\n",
        "  \n",
        "  print('old attributed skills file loaded')\n",
        "  print('utilizing known attributes to create a new file that includes the new skills')\n",
        "\n",
        "  try:\n",
        "    df_new=pd.read_excel(skills_list_new_filename_i,index_col=0)\n",
        "  except:\n",
        "    print('error loading '+skills_list_new_filename_i+' as the new skills list')\n",
        "    return\n",
        "  df=df_new\n",
        "  mask=df_new.isin(list(df_old['skill'])) #masks what skills are re-usable\n",
        "  indexes_to_update=df_new[mask['skill']].index #gets their indexes\n",
        "  for i in indexes_to_update: #for each of the marked skills\n",
        "    skill=df_new.loc[i,'skill'] #checks the skill name\n",
        "    row=df_old[df_old['skill']==skill] #search the skill name and gets the row (with the attributes values) from the old dataframe\n",
        "    row.index=[i] #corrects its index with the value in the new dataframe\n",
        "    df=df.drop(i) #erases the \"empty\" row in the new dataframe\n",
        "    df=pd.concat([df,row]) #ads the \"filled\" row to the new dataframe\n",
        "  if sort==True: #not sorting the dataframe means the new spells (with pending attributes assignments) will all be at the top\n",
        "    df=df.sort_index() #sorts the dataframe if wanted\n",
        "  df.to_excel(skills_attributed_filename_io)\n",
        "  print('new skill list attributed: '+skills_attributed_filename_io)\n",
        "  print('dont forget to review it and create a copy as: '+skills_list_attributed_backup_i)"
      ],
      "metadata": {
        "id": "7P3cD53GRVdS"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#function to be used when an update adds (or removes) skills or heroes\n",
        "#uses update_hero_list(), update_skills_list() and update_attribute_data()\n",
        "def new_skillhero(last_hero='ZEUS',skills_list_attributed_io='skills_list_attributed.xlsx',hero_filename_o='hero_list.xlsx',\n",
        "                    skill_filename_o='skills_list.xlsx',skills_list_attributed_backup_i='skills_list_attributed_backup.xlsx'):\n",
        "  \n",
        "  anythingnew=update_hero_list(last_hero,hero_filename_o)\n",
        "  if anythingnew==False:\n",
        "    print('aborting new_skillhero()')\n",
        "    return\n",
        "\n",
        "  update_skills_list(skill_filename_o,hero_filename_o)\n",
        "\n",
        "  update_attribute_data(skill_filename_o,skills_list_attributed_io,skills_list_attributed_backup_i)"
      ],
      "metadata": {
        "id": "UAmGaQ7nis38"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ano10t-2DEFq"
      },
      "source": [
        "#function updates hero win and pickrates from www.dotabuff.com\n",
        "def update_win_pick(hero_list_filename_i='hero_list.xlsx'):\n",
        "  print('updating win and pick rates')\n",
        "  print('expected time: ~1min')\n",
        "\n",
        "  try:\n",
        "    df_winpick=pd.read_excel(hero_list_filename_i,index_col=0,usecols=[1])\n",
        "  except:\n",
        "    print('error loading '+hero_list_filename_i+' as the hero list')\n",
        "    return\n",
        "\n",
        "  wd.delete_all_cookies()\n",
        "  wd.get(\"https://www.dotabuff.com/heroes/trends\")\n",
        "  wd.page_source;\n",
        "  time.sleep(2)\n",
        "\n",
        "  data_coord=[2,3,4,6,7,8] #list used to form the xpath. more at the end of the code\n",
        "  data=[]\n",
        "\n",
        "  total_heroes=df_winpick.shape[0]\n",
        "\n",
        "  order_name_b=wd.find_element('xpath','/html/body/div[2]/div[2]/div[3]/div[4]/section/article/table/thead/tr[3]/th[1]') #\n",
        "  order_name_b.click()  #orders table by hero name\n",
        "\n",
        "  for j in range(total_heroes): #iterates row (heroes)\n",
        "    data_row=[]\n",
        "    for i in range(len(data_coord)): #iterates data (win rate, pick rate, etc)\n",
        "      xpath='/html/body/div[2]/div[2]/div[3]/div[4]/section/article/table/tbody/tr['+str(j+1)+']/td['+str(data_coord[i])+']'\n",
        "      html_element=wd.find_element('xpath',xpath)\n",
        "      try:\n",
        "        data_row+=[float(html_element.text.replace('%','').replace('+',''))] #removes % and + signs, converts to float and adds to the list\n",
        "      except:\n",
        "        data_row+=[0]\n",
        "\n",
        "    data.append(data_row)\n",
        "\n",
        "  df_winpick[['WIN_RATE_OLD','WIN_RATE','WIN_RATE_VAR','PICK_RATE_OLD','PICK_RATE','PICK_RATE_VAR']]=data\n",
        "  timestr=datetime.now(pytz.timezone('America/Sao_Paulo')).strftime('%Y%m%d') #time in BRT(GMT-3): year month day\n",
        "  df_winpick.to_excel('winpick'+timestr+'.xlsx')\n",
        "  print('created '+'winpick'+timestr+'.xlsx')\n",
        "\n",
        "  # xpaths. last checked 23 june 2022\n",
        "  # first hero\n",
        "  # /html/body/div[2]/div[2]/div[3]/div[4]/section/article/table/tbody/tr[1]/td[2]  old_win\n",
        "  # /html/body/div[2]/div[2]/div[3]/div[4]/section/article/table/tbody/tr[1]/td[3]  new_win\n",
        "  # /html/body/div[2]/div[2]/div[3]/div[4]/section/article/table/tbody/tr[1]/td[4]  change_win\n",
        "  # /html/body/div[2]/div[2]/div[3]/div[4]/section/article/table/tbody/tr[1]/td[6]  old_pick\n",
        "  # /html/body/div[2]/div[2]/div[3]/div[4]/section/article/table/tbody/tr[1]/td[7]  new_pick\n",
        "  # /html/body/div[2]/div[2]/div[3]/div[4]/section/article/table/tbody/tr[1]/td[8]  change_pick\n",
        "  # second hero\n",
        "  # /html/body/div[2]/div[2]/div[3]/div[4]/section/article/table/tbody/tr[2]/td[2]  old_win\n",
        "  # /html/body/div[2]/div[2]/div[3]/div[4]/section/article/table/tbody/tr[2]/td[3]  new_win"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5KF6J6YfQ4d3"
      },
      "source": [
        "#to take a screenshot from chrome\n",
        "\n",
        "# from PIL import Image\n",
        "# from io import BytesIO\n",
        "\n",
        "# figure=wd.get_screenshot_as_png()\n",
        "# im = Image.open(BytesIO(figure))\n",
        "# im"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "UX3mZOrE_y1W"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}